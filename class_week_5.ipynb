{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.1.66.155:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 (continued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Example 5\n",
    "text1 = sc.textFile('/Users/owner/USF/spark/filtered_registered_business_sf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'94123,Tournahu George L,3301 Broderick St,San Francisco,CA',\n",
       " u'94124,Stephens Institute Inc,2225 Jerrold Ave,San Francisco,CA',\n",
       " u'94105,Stephens Institute Inc,180 New Montgomery St,San Francisco,CA',\n",
       " u'94108,Stephens Institute Inc,540 Powell St,San Francisco,CA',\n",
       " u'94107,Stephens Institute Inc,460 Townsend St,San Francisco,CA',\n",
       " u'94109,Stephens Institute Inc,1835-49 Van Ness Ave,San Francisco,CA',\n",
       " u'94102,Stephens Institute Inc,620 Sutter St,San Francisco,CA',\n",
       " u'94102,Stephens Institute Inc,655 Sutter St,San Francisco,CA',\n",
       " u'94109,Stephens Institute Inc,1055 Pine St,San Francisco,CA',\n",
       " u'94107,Stephens Institute Inc,121 Wisconsin St,San Francisco,CA']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a (key,value) pair: (zip,(store name, city))\n",
    "zip_store_city=text1.map(lambda x:x.split(',')).map(lambda x: (x[0],(x[1],x[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count pairs which do not have a key.\n",
    "zip_store_city.countByKey()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter pairs that do not include “San Francisco” in the city value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Spark - Persist in Memory/Disk\n",
    "\n",
    "**Pesistency Level**\n",
    "\n",
    "- MEMORY_ONLY\n",
    "- MEMORY_AND_DISK\n",
    "\n",
    "...\n",
    "\n",
    "- MEMORY_ONLY_2, MEMORY_AND_DISK_2 ETC.. - (Best practice to allocate on 3 clusters - alk about this later in January)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use **```.persist(storage_level)```**\n",
    "\n",
    "OR\n",
    "\n",
    "**```.cache() = .persist(MEMORY_ONLY) = .Persist()```**\n",
    "\n",
    "To change form MEMORY_ONLY to MEMORY_AND_DISK, you have to first run **```.unpersist()```**,  otherwise Error will be thrown up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the persistence level\n",
    "\n",
    "- getStorageLevel(): checks if it uses Disk, Memory , at external system, as deserialized Java objects, replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **MEMORY_ONLY**  is the **best**\n",
    "\n",
    "- **Disk**: only if recomputation is expensive and cannot fit the memory \n",
    "\n",
    "- **off-Heap**: Stored outside of the Spark executor in an external system ==> use when there is memory issue/noisy cluster (when somehting happens to your cluster and \n",
    "\n",
    "- **Serialization** - it makes objects smaller. So, when the job is too big to fit into memory, serialization could be done\n",
    "\n",
    "- **Replication** - faster fault recovery. Cost more space/speed ==> use when bad connection between the nodes happens often / live web app.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise 7\n",
    "lines = sc.textFile(\"README.md\")\n",
    "\n",
    "lines_with_spark=lines.filter(lambda x: \"Spark\" in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, False, False, False, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "lines_with_spark.getStorageLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_spark.persist(StorageLevel(False,True, False, False,3))\n",
    "lines_with_spark.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 5\n",
    "### SPARK ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Client** \n",
    "- Start driver\n",
    "- Config \n",
    "\n",
    "\n",
    "==>\n",
    "\n",
    "**Driver**\n",
    "- Orchestrate executors\n",
    "- Send tasks to executors\n",
    "- receive results from executors\n",
    "\n",
    "==>\n",
    "\n",
    "**Executor(s)**\n",
    "\n",
    "- execute tasks\n",
    "- store data\n",
    "- return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
